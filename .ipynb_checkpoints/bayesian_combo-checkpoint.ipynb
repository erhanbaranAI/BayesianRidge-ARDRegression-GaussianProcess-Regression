{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6d606-ae29-4992-abf8-fc17705d54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58332c85-7217-4421-a810-74c55fe4ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def preprocess_dataset_train(file_path):\n",
    "    \"\"\"\n",
    "    Train veri setini hazÄ±rlar: Eksik deÄŸerleri doldurur, kategorik deÄŸiÅŸkenleri iÅŸler,\n",
    "    log dÃ¶nÃ¼ÅŸÃ¼mÃ¼ uygular, dÃ¼ÅŸÃ¼k korelasyonlu sÃ¼tunlarÄ± temizler ve IQR yÃ¶ntemiyle aykÄ±rÄ±\n",
    "    deÄŸerleri sÄ±nÄ±rlar.\n",
    "    \"\"\"\n",
    "    # ðŸ“Œ 1. CSV dosyasÄ±nÄ± oku\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"âœ… Veri yÃ¼klendi: {df.shape}\")\n",
    "\n",
    "    # ðŸŸ¢ 2. Log dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ uygula (Ã–NEMLÄ°!)\n",
    "    df[\"SalePrice\"] = np.log1p(df[\"SalePrice\"])\n",
    "    print(\"âœ… Log dÃ¶nÃ¼ÅŸÃ¼mÃ¼ uygulandÄ±!\")\n",
    "\n",
    "    # ðŸŸ¢ 3. Eksik deÄŸerleri doldur\n",
    "    df[\"GarageYrBlt\"].fillna(0, inplace=True)\n",
    "    df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "    df[\"MasVnrArea\"].fillna(0, inplace=True)\n",
    "    print(\"âœ… Eksik deÄŸerler dolduruldu!\")\n",
    "\n",
    "    # ðŸŸ¢ 4. Ordinal Encoding Uygula\n",
    "    ordinal_features = {\n",
    "        \"ExterQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1},\n",
    "        \"ExterCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1},\n",
    "        \"BsmtQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        \"BsmtCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        \"KitchenQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1},\n",
    "        \"FireplaceQu\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        \"GarageQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        \"GarageCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        \"PoolQC\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"NA\": 0},\n",
    "        \"Fence\": {\"GdPrv\": 4, \"MnPrv\": 3, \"GdWo\": 2, \"MnWw\": 1, \"NA\": 0}\n",
    "    }\n",
    "    \n",
    "    for col, mapping in ordinal_features.items():\n",
    "        df[col] = df[col].map(mapping)\n",
    "\n",
    "    print(\"âœ… Ordinal Encoding tamamlandÄ±!\")\n",
    "\n",
    "    # ðŸŸ¢ 5. One-Hot Encoding\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "    print(\"âœ… One-Hot Encoding tamamlandÄ±!\")\n",
    "\n",
    "    # ðŸŸ¢ 6. SalePrice ile dÃ¼ÅŸÃ¼k korelasyonlu sÃ¼tunlarÄ± kaldÄ±r\n",
    "    correlation_threshold = 0.05\n",
    "    corr_with_saleprice = df.corr()[\"SalePrice\"].abs()\n",
    "    low_corr_features = corr_with_saleprice[corr_with_saleprice < correlation_threshold].index\n",
    "    df.drop(columns=low_corr_features, inplace=True)\n",
    "    print(f\"âœ… DÃ¼ÅŸÃ¼k korelasyonlu {len(low_corr_features)} sÃ¼tun kaldÄ±rÄ±ldÄ±!\")\n",
    "\n",
    "    # ðŸŸ¢ 7. SayÄ±sal deÄŸiÅŸkenlerdeki eksik deÄŸerleri MEDIAN ile doldur\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    missing_before = df[numerical_cols].isna().sum().sum()\n",
    "    df[numerical_cols] = df[numerical_cols].apply(lambda x: x.fillna(x.median()))\n",
    "    print(f\"âœ… SayÄ±sal eksik deÄŸerler median ile dolduruldu! Toplam deÄŸiÅŸtirilen hÃ¼cre sayÄ±sÄ±: {missing_before}\")\n",
    "\n",
    "    # ðŸŸ¢ 8. AykÄ±rÄ± DeÄŸerleri IQR ile KÄ±rp\n",
    "    def remove_outliers_iqr(df, columns):\n",
    "        for col in columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            df[col] = np.clip(df[col], lower_bound, upper_bound)\n",
    "        return df\n",
    "\n",
    "    df = remove_outliers_iqr(df, numerical_cols)\n",
    "    print(\"âœ… AykÄ±rÄ± deÄŸerler IQR yÃ¶ntemiyle kÄ±rpÄ±ldÄ±!\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b9434d-0d36-4d40-9c49-d7cb116c794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train veri setini iÅŸle\n",
    "train_prepared = preprocess_dataset_train(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7bc13-365f-48b8-a419-4098c7e293b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge, ARDRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_cnn(train_df):\n",
    "    \"\"\"\n",
    "    Bayesian Ridge, ARD Regression ve Gaussian Process Regression kullanarak eÄŸitim yapar.\n",
    "    \"\"\"\n",
    "    y = train_df[\"SalePrice\"]\n",
    "    X = train_df.drop(columns=[\"SalePrice\"])\n",
    "\n",
    "    # Train-Test AyÄ±rma\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # SayÄ±sal veriyi Ã¶lÃ§eklendir\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # ðŸ“Œ **1. Bayesian Ridge Regression**\n",
    "    bayesian_ridge = BayesianRidge()\n",
    "    bayesian_ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # ðŸ“Œ **2. ARD Regression**\n",
    "    ard_regression = ARDRegression()\n",
    "    ard_regression.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # ðŸ“Œ **3. Gaussian Process Regression (GPR)**\n",
    "    kernel = RationalQuadratic()  # GPR iÃ§in uygun kernel seÃ§imi\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
    "    gpr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # ðŸ“Œ **Model Tahminleri (Averaging)**\n",
    "    y_pred_ridge = bayesian_ridge.predict(X_test_scaled)\n",
    "    y_pred_ard = ard_regression.predict(X_test_scaled)\n",
    "    y_pred_gpr = gpr.predict(X_test_scaled)\n",
    "\n",
    "    # 3 modelin ortalamasÄ±nÄ± alarak ensembled tahmin yapalÄ±m\n",
    "    final_preds = (y_pred_ridge + y_pred_ard + y_pred_gpr) / 3\n",
    "\n",
    "    # R^2 skorlarÄ±nÄ± yazdÄ±r\n",
    "    r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "    r2_ard = r2_score(y_test, y_pred_ard)\n",
    "    r2_gpr = r2_score(y_test, y_pred_gpr)\n",
    "    r2_final = r2_score(y_test, final_preds)\n",
    "\n",
    "    print(f\"âœ… Bayesian Ridge RÂ²: {r2_ridge:.4f}\")\n",
    "    print(f\"âœ… ARD Regression RÂ²: {r2_ard:.4f}\")\n",
    "    print(f\"âœ… Gaussian Process Regression RÂ²: {r2_gpr:.4f}\")\n",
    "    print(f\"âœ… Ensemble Model RÂ²: {r2_final:.4f}\")\n",
    "\n",
    "    # Modeli dÃ¶ndÃ¼r\n",
    "    return {\n",
    "        \"bayesian_ridge\": bayesian_ridge,\n",
    "        \"ard_regression\": ard_regression,\n",
    "        \"gpr\": gpr,\n",
    "        \"scaler\": scaler\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e45318-ba93-4519-a0d6-1fa0c5405526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_dataset_test(file_path, train_columns):\n",
    "    \"\"\"\n",
    "    Test veri setini iÅŸler ve train setindeki sÃ¼tunlarla uyumlu hale getirir.\n",
    "    - Eksik deÄŸerleri doldurur.\n",
    "    - Kategorik deÄŸiÅŸkenleri iÅŸler.\n",
    "    - One-Hot Encoding uygular.\n",
    "    - Eksik sÃ¼tunlarÄ± sÄ±fÄ±r ile doldurur.\n",
    "    \"\"\"\n",
    "    # ðŸ“Œ 1. CSV dosyasÄ±nÄ± oku\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"âœ… Test verisi yÃ¼klendi: {df.shape}\")\n",
    "\n",
    "    # ðŸŸ¢ 2. GarageYrBlt, LotFrontage ve MasVnrArea eksik deÄŸerlerini doldur\n",
    "    df[\"GarageYrBlt\"].fillna(0, inplace=True)\n",
    "    df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "    df[\"MasVnrArea\"].fillna(0, inplace=True)\n",
    "\n",
    "    print(\"âœ… Eksik deÄŸerler dolduruldu!\")\n",
    "\n",
    "    # ðŸŸ¢ 3. Ordinal Encoding Uygula\n",
    "    ordinal_features = {\n",
    "        \"ExterQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1},\n",
    "        \"ExterCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1},\n",
    "        \"BsmtQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        \"BsmtCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        \"KitchenQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1},\n",
    "        \"FireplaceQu\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        \"GarageQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        \"GarageCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        \"PoolQC\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"NA\": 0},\n",
    "        \"Fence\": {\"GdPrv\": 4, \"MnPrv\": 3, \"GdWo\": 2, \"MnWw\": 1, \"NA\": 0}\n",
    "    }\n",
    "    \n",
    "    for col, mapping in ordinal_features.items():\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(mapping)\n",
    "\n",
    "    print(\"âœ… Ordinal Encoding tamamlandÄ±!\")\n",
    "\n",
    "    # ðŸŸ¢ 4. One-Hot Encoding Uygula\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "    print(\"âœ… One-Hot Encoding tamamlandÄ±!\")\n",
    "\n",
    "    # ðŸŸ¢ 5. Train veri setindeki sÃ¼tunlarla test verisini uyumlu hale getir\n",
    "    missing_cols = set(train_columns) - set(df.columns)\n",
    "    for col in missing_cols:\n",
    "        df[col] = 0  # Eksik sÃ¼tunlarÄ± sÄ±fÄ±r ile doldur\n",
    "    \n",
    "    df = df[train_columns]  # Fazla olan sÃ¼tunlarÄ± kaldÄ±r\n",
    "\n",
    "    print(f\"âœ… Test seti, train setiyle uyumlu hale getirildi! Yeni ÅŸekil: {df.shape}\")\n",
    "\n",
    "    # ðŸŸ¢ 6. Eksik SayÄ±sal DeÄŸerleri Median ile Doldur\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    missing_before = df[numerical_cols].isna().sum().sum()\n",
    "    df[numerical_cols] = df[numerical_cols].apply(lambda x: x.fillna(x.median()))\n",
    "    print(f\"âœ… SayÄ±sal eksik deÄŸerler median ile dolduruldu! Toplam deÄŸiÅŸtirilen hÃ¼cre sayÄ±sÄ±: {missing_before}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c19ba54-768e-430d-9f53-82cd7c7dac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def test_cnn(models, test_df, test_csv_path, output_csv=\"bayesian-submission.csv\"):\n",
    "    \"\"\"\n",
    "    Bayesian model kombinasyonlarÄ± ile test verisini tahmin eder.\n",
    "    Log dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ ters Ã§evirerek gerÃ§ek deÄŸerleri verir ve aÅŸÄ±rÄ± bÃ¼yÃ¼k deÄŸerleri sÄ±nÄ±rlayarak `inf` hatasÄ±nÄ± engeller.\n",
    "    \"\"\"\n",
    "    # ðŸ“Œ 1. Test verisini yÃ¼kle\n",
    "    test_raw = pd.read_csv(test_csv_path)\n",
    "    test_ids = test_raw[\"Id\"]  # Orijinal test setindeki ID'leri al\n",
    "\n",
    "    # ðŸ“Œ 2. Veriyi Ã¶lÃ§eklendir\n",
    "    test_df_scaled = models[\"scaler\"].transform(test_df)\n",
    "\n",
    "    # ðŸ“Œ 3. Modeller ile tahmin yap\n",
    "    pred_ridge = models[\"bayesian_ridge\"].predict(test_df_scaled)\n",
    "    pred_ard = models[\"ard_regression\"].predict(test_df_scaled)\n",
    "    pred_gpr = models[\"gpr\"].predict(test_df_scaled)\n",
    "\n",
    "    # ðŸ“Œ 4. 3 modelin ortalama tahminini hesapla\n",
    "    predictions_log = (pred_ridge + pred_ard + pred_gpr) / 3\n",
    "\n",
    "    # ðŸ“Œ 5. Log dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ geri al\n",
    "    predictions = np.expm1(predictions_log)\n",
    "\n",
    "    # ðŸ“Œ 6. `inf` hatasÄ±nÄ± Ã¶nlemek iÃ§in tahminleri sÄ±nÄ±rlÄ± aralÄ±ÄŸa Ã§ek\n",
    "    predictions = np.nan_to_num(predictions, nan=0.0, posinf=700000, neginf=0.0)\n",
    "\n",
    "    # ðŸ“Œ 7. Tahminleri kaydet\n",
    "    submission = pd.DataFrame({\"Id\": test_ids, \"SalePrice\": predictions})\n",
    "    submission.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"âœ… Tahminler {output_csv} dosyasÄ±na kaydedildi! (Ä°Ã§erik KontrolÃ¼: {submission.describe()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71910efa-317d-4c9c-98b0-bde4c4feb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnn_model = train_cnn(train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616c116-5754-40f0-aec0-f23eea42c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ 1. Test veri setini iÅŸle (train veri setiyle uyumlu hale getir)\n",
    "test_prepared = preprocess_dataset_test(\"test.csv\", train_prepared.drop(columns=[\"SalePrice\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f03c944-3440-49cd-b984-93df9899b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ 1. Test verisini hazÄ±rla ve modeli test et\n",
    "test_cnn(train_cnn_model, test_prepared, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a17e48-aed7-4caf-85d3-4834dd306710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
